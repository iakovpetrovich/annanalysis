{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport os\nimport struct\nimport pandas as pd\nimport time\nfrom time import process_time\nfrom itertools import chain \nimport gc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["dataset = 'smallSift'\n\nif dataset == 'sift':\n  url = \"ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\"\n  paths =  '/tmp/sift.tar.gz' \n  trainPath = 'sift/sift_base.fvecs'\n  queryPath = 'sift/sift_query.fvecs'\n  groundPath = 'sift/sift_groundtruth.ivecs'\n  \nif dataset == 'smallSift':\n  url = 'ftp://ftp.irisa.fr/local/texmex/corpus/siftsmall.tar.gz'\n  paths =  '/tmp/siftsmall.tar.gz' \n  trainPath = 'siftsmall/siftsmall_base.fvecs'\n  queryPath = 'siftsmall/siftsmall_query.fvecs'\n  groundPath = 'siftsmall/siftsmall_groundtruth.ivecs'\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["import urllib \nurllib.request.urlretrieve(url, paths)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: (&#39;/tmp/siftsmall.tar.gz&#39;, &lt;email.message.Message at 0x7f74f431b5d0&gt;)</div>"]}}],"execution_count":4},{"cell_type":"code","source":["def get_zippedFvecs(pathToGz,memeber):\n    import tarfile\n    fn = pathToGz\n    import struct\n    import numpy as np\n    t = tarfile.open(fn, 'r:gz') \n    \n    \n    m = t.getmember(memeber)\n    file = t.extractfile(m)\n    fileSize = m.size\n    #file =  open(path,'rb')\n    #first 4 bytes of every vector indicate number od dimensions \n    numOfDimensions = struct.unpack('i', file.read(4))[0]\n    #each vector has 4 bytes (float is 32 bits) * numberOfDimensions\n    #plus 4 bytes long indicator as mentioned  \n    numOfVectors = (int) (fileSize / (4 + 4*numOfDimensions))\n    #init empty list for vectors\n    #vectors = []\n    vectors = np.zeros((numOfVectors,numOfDimensions))\n    #return to the beginning\n    file.seek(0)\n    for vecotr in range(numOfVectors):\n        file.read(4) #go trough indicator of dimensions\n        #vectors.append(struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions)))\n        vectors[vecotr] = struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions))\n    file.close()\n    return vectors"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["\ndef get_zippedIvecs(pathToGz,memeber):\n    import tarfile\n    fn = pathToGz\n    import struct\n    import numpy as np\n    t = tarfile.open(fn, 'r:gz') \n    \n    \n    m = t.getmember(memeber)\n    file = t.extractfile(m)\n    fileSize = m.size\n    #file =  open(path,'rb')\n    #first 4 bytes of every vector indicate number od dimensions \n    numOfDimensions = struct.unpack('i', file.read(4))[0]\n    #each vector has 4 bytes (float is 32 bits) * numberOfDimensions\n    #plus 4 bytes long indicator as mentioned  \n    numOfVectors = (int) (fileSize / (4 + 4*numOfDimensions))\n    #init empty list for vectors\n    #vectors = []\n    vectors = np.zeros((numOfVectors,numOfDimensions), int)\n    #return to the beginning\n    file.seek(0)\n    for vecotr in range(numOfVectors):\n        file.read(4) #go trough indicator of dimensions\n        #vectors.append(struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions)))\n        vectors[vecotr] = struct.unpack('i' * numOfDimensions, file.read(4*numOfDimensions))\n    file.close()\n    return vectors\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def returnRecall(result, test):\n    numOfTrueNeighbours = []\n    #for every result vector we check how many right neighbours were identified\n    for i in range(result.shape[0]):\n        numTN = len(set(result[i].tolist()) & set(test[i].tolist()))\n        numOfTrueNeighbours.append(numTN)\n        recall = sum(numOfTrueNeighbours) /test.size\n    return recall"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["def fillIfNotAllAreFound(result):\n    for i in range(len(result)):\n        if len(result[i]) < 100: \n            result[i].extend((100-len(result[i])) *[-1]) \n    return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["train = get_zippedFvecs(paths,trainPath )\n#there is 100 querry ponts\nquery = get_zippedFvecs(paths,queryPath )\n#there is index number of 100 nearset n. for each querry point\ngroundTruth = get_zippedIvecs(paths,groundPath )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["rm /tmp/sift.tar.gz"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["algorithm = []\nconstruciotnTimes=[]\nsearchTimes=[]\nreacll = []\nk = 100\navgdistances = []\nconstructionClocks = []\nsearchClocks = []\nclockAlg = []"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["#Annoy\nfrom annoy import AnnoyIndex\nfor trs in [5,15,30,60,80]:\n    \n    f = train.shape[1]\n    t = AnnoyIndex(f, 'euclidean')\n    \n    startClock= time.clock()\n    startTime = process_time()\n    for i in range(train.shape[0]):\n        t.add_item(i,train[i])\n    t.build(trs)\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    rez = []\n    dist = []\n    startClock = time.clock()\n    startTime = process_time()\n    for q in query:\n        res,d = t.get_nns_by_vector(q, 100, include_distances=True)\n        rez.append(res)\n        dist.append(d)\n        #result.append(t.get_nns_by_vector(q, 100, include_distances=True))\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n        \n    result = fillIfNotAllAreFound(rez)\n    \n    result = np.asanyarray(result)\n    annoyRecall = returnRecall(result, groundTruth)  \n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(annoyRecall)\n    algorithm.append('Annoy-trees-'+str(trs))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    searchClocks.append(searchClock)\n    constructionClocks.append(constructionClock)\n    clockAlg.append('Annoy-trees-'+str(trs))\n    t.save('annoyIndex90.ann')\n    del t\n    del rez\n    del dist\n    del result\n    gc.collect()\n#______________________________________________#\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3193702701822154&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-green-fg\">for</span> trs <span class=\"ansi-green-fg\">in</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">30</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">60</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">80</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">     </span>f <span class=\"ansi-blue-fg\">=</span> train<span class=\"ansi-blue-fg\">.</span>shape<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     t <span class=\"ansi-blue-fg\">=</span> AnnoyIndex<span class=\"ansi-blue-fg\">(</span>f<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;euclidean&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;train&#39; is not defined</div>"]}}],"execution_count":12},{"cell_type":"code","source":["import nmslib\nfor MMAX in [5,8,15,30,38]:\n    hnsw = nmslib.init(method='hnsw', space='l2')\n    \n    startClock = time.clock()\n    startTime = process_time()\n    hnsw.addDataPointBatch(train)\n    hnsw.createIndex({'delaunay_type':1, 'M':MMAX})\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    \n    # get all nearest neighbours for all the datapoint\n    # using a pool of 4 threads to compute\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = hnsw.knnQueryBatch(query, k=100, num_threads=2)\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    rez =[]\n    dist =[]\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n    \n    result = fillIfNotAllAreFound(rez)\n      \n    result = np.array(rez)\n    hnswRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(np.sqrt(list(chain.from_iterable(dist))))\n    \n    reacll.append(hnswRecall)\n    algorithm.append('HNSW-M-'+str(MMAX))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    clockAlg.append('HNSW-M-'+str(MMAX))\n    \n    del hnsw\n    del rez\n    del dist\n    del result\n    del neighbours\n    gc.collect()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3193702701822153&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     startClock <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>clock<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     startTime <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\">     </span>hnsw<span class=\"ansi-blue-fg\">.</span>addDataPointBatch<span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>     hnsw<span class=\"ansi-blue-fg\">.</span>createIndex<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#39;delaunay_type&#39;</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;M&#39;</span><span class=\"ansi-blue-fg\">:</span>MMAX<span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>     end_time <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;train&#39; is not defined</div>"]}}],"execution_count":13},{"cell_type":"code","source":["import nmslib\nvptree = nmslib.init(method='vptree', space='l2')\n\nstartClock = time.clock()\nstartTime = process_time()\nvptree.addDataPointBatch(train)\nvptree.createIndex({'bucketSize' : 10000,'selectPivotAttempts':10})\nend_time = process_time()\nconstructionTime = end_time - startTime\nendClock = time.clock()\nconstructionClock= endClock - startClock\n\n# get all nearest neighbours for all the datapoint\n# using a pool of 4 threads to compute\nfor maxLeave in [2,10,20,25,30]:\n  \n    vptree.setQueryTimeParams({'maxLeavesToVisit':maxLeave,'alphaLeft':1.1,'alphaRight':1.1})\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = vptree.knnQueryBatch(query,k=100, num_threads=2 )\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    \n    rez =[]\n    dist = []\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n        \n    rez = fillIfNotAllAreFound(rez)    \n    \n    result = np.asanyarray(rez)\n    \n    vptreeRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(vptreeRecall)\n    algorithm.append('vp-Tree-10k-mL'+str(maxLeave))\n    #algorithm.append('vp-Tree-maxLeaves'+str(maxLeaves))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    avgdistances.append(avgDist)\n    del rez\n    del dist\n    del result\n    gc.collect()\n\n#vptree.saveIndex('vptreeIndex.ann')    \ndel vptree\ngc.collect()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3193702701822151&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> startClock <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>clock<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> startTime <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>vptree<span class=\"ansi-blue-fg\">.</span>addDataPointBatch<span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> vptree<span class=\"ansi-blue-fg\">.</span>createIndex<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#39;bucketSize&#39;</span> <span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-cyan-fg\">10000</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;selectPivotAttempts&#39;</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> end_time <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;train&#39; is not defined</div>"]}}],"execution_count":14},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["compareResults = pd.DataFrame({ 'algorithm':algorithm, 'constructionTime':construciotnTimes, 'searchTime':searchTimes,'recall':reacll,'avgDistance':avgdistances, 'constructionClocks':constructionClocks,'searchClocks':searchClocks})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["compareResults"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithm</th>\n      <th>constructionTime</th>\n      <th>searchTime</th>\n      <th>recall</th>\n      <th>avgDistance</th>\n      <th>constructionClocks</th>\n      <th>searchClocks</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["display(compareResults)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-913127357586025&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>compareResults<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1598775860123-0/PythonShell.py</span> in <span class=\"ansi-cyan-fg\">display</span><span class=\"ansi-blue-fg\">(self, input, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1095</span>             <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>sparkSession <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1096</span>                 <span class=\"ansi-green-fg\">raise</span> Exception<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;SparkSession is required for display(pandas.DataFrame).&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1097</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>display<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>sparkSession<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1098</span>         <span class=\"ansi-green-fg\">elif</span> type<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__module__ <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#39;databricks.koalas.frame&#39;</span> <span class=\"ansi-green-fg\">and</span> type<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__name__ <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#39;DataFrame&#39;</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1099</span>             index_col <span class=\"ansi-blue-fg\">=</span> kwargs<span class=\"ansi-blue-fg\">.</span>get<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;index_col&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    650</span>             <span class=\"ansi-red-fg\"># Create a DataFrame from pandas DataFrame.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    651</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-fg\">--&gt; 652</span><span class=\"ansi-red-fg\">                 data, schema, samplingRatio, verifySchema)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    653</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    654</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/pandas/conversion.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    300</span>                     <span class=\"ansi-green-fg\">raise</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    301</span>         data <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_convert_from_pandas<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> timezone<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 302</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    303</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    304</span>     <span class=\"ansi-green-fg\">def</span> _convert_from_pandas<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pdf<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> timezone<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    683</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    684</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 685</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    686</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    687</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    468</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    469</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 470</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    471</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    472</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    447</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    448</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 449</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    450</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    451</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    378</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    379</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 380</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    381</span>         first <span class=\"ansi-blue-fg\">=</span> data<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    382</span>         <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>first<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">is</span> dict<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: can not infer schema from empty dataset</div>"]}}],"execution_count":18},{"cell_type":"code","source":["compareResults.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"dbfs:/FileStore/df/compareResults.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-913127357586026&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>compareResults<span class=\"ansi-blue-fg\">.</span>coalesce<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;com.databricks.spark.csv&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;header&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;true&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>save<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbfs:/FileStore/df/compareResults.csv&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pandas/core/generic.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   5272</span>             <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_info_axis<span class=\"ansi-blue-fg\">.</span>_can_hold_identifiers_and_holds_name<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   5273</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">[</span>name<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">-&gt; 5274</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> object<span class=\"ansi-blue-fg\">.</span>__getattribute__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   5275</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   5276</span>     <span class=\"ansi-green-fg\">def</span> __setattr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">:</span> str<span class=\"ansi-blue-fg\">,</span> value<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;coalesce&#39;</div>"]}}],"execution_count":19},{"cell_type":"code","source":["import nmslib\nvptree = nmslib.init(method='vptree', space='l2')\n\nstartClock = time.clock()\nstartTime = process_time()\nvptree.addDataPointBatch(train)\nvptree.createIndex({'bucketSize' : 10000,'selectPivotAttempts':10})\nend_time = process_time()\nconstructionTime = end_time - startTime\nendClock = time.clock()\nconstructionClock= endClock - startClock\n\n# get all nearest neighbours for all the datapoint\n# using a pool of 4 threads to compute\nfor maxLeave in [2,10,20,25,30]:\n  \n    vptree.setQueryTimeParams({'maxLeavesToVisit':maxLeave,'alphaLeft':1.1,'alphaRight':1.1})\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = vptree.knnQueryBatch(query,k=100, num_threads=2 )\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    \n    rez =[]\n    dist = []\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n        \n    rez = fillIfNotAllAreFound(rez)    \n    \n    result = np.asanyarray(rez)\n    \n    vptreeRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(vptreeRecall)\n    algorithm.append('vp-Tree-10k-mL'+str(maxLeave))\n    #algorithm.append('vp-Tree-maxLeaves'+str(maxLeaves))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    avgdistances.append(avgDist)\n    del rez\n    del dist\n    del result\n    gc.collect()\n\n#vptree.saveIndex('vptreeIndex.ann')    \ndel vptree\ngc.collect()\n\n\n#HNSW da bi islo po redu\n#______________________________________________#\nimport nmslib\nfor MMAX in [5,8,15,30,38]:\n    hnsw = nmslib.init(method='hnsw', space='l2')\n    \n    startClock = time.clock()\n    startTime = process_time()\n    hnsw.addDataPointBatch(train)\n    hnsw.createIndex({'delaunay_type':1, 'M':MMAX})\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    \n    # get all nearest neighbours for all the datapoint\n    # using a pool of 4 threads to compute\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = hnsw.knnQueryBatch(query, k=100, num_threads=2)\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    rez =[]\n    dist =[]\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n    \n    result = fillIfNotAllAreFound(rez)\n      \n    result = np.array(rez)\n    hnswRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(np.sqrt(list(chain.from_iterable(dist))))\n    \n    reacll.append(hnswRecall)\n    algorithm.append('HNSW-M-'+str(MMAX))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    clockAlg.append('HNSW-M-'+str(MMAX))\n    \n    del hnsw\n    del rez\n    del dist\n    del result\n    del neighbours\n    gc.collect()\n\n#______________________________________________#    \n#annoy\n#Annoy\nfrom annoy import AnnoyIndex\nfor trs in [5,15,30,60,80]:\n    \n    f = train.shape[1]\n    t = AnnoyIndex(f, 'euclidean')\n    \n    startClock= time.clock()\n    startTime = process_time()\n    for i in range(train.shape[0]):\n        t.add_item(i,train[i])\n    t.build(trs)\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    rez = []\n    dist = []\n    startClock = time.clock()\n    startTime = process_time()\n    for q in query:\n        res,d = t.get_nns_by_vector(q, 100, include_distances=True)\n        rez.append(res)\n        dist.append(d)\n        #result.append(t.get_nns_by_vector(q, 100, include_distances=True))\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n        \n    result = fillIfNotAllAreFound(rez)\n    \n    result = np.asanyarray(result)\n    annoyRecall = returnRecall(result, groundTruth)  \n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(annoyRecall)\n    algorithm.append('Annoy-trees-'+str(trs))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    searchClocks.append(searchClock)\n    constructionClocks.append(constructionClock)\n    clockAlg.append('Annoy-trees-'+str(trs))\n    t.save('annoyIndex90.ann')\n    del t\n    del rez\n    del dist\n    del result\n    gc.collect()\n#______________________________________________#\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1518425739103876&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> startClock <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>clock<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> startTime <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>vptree<span class=\"ansi-blue-fg\">.</span>addDataPointBatch<span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> vptree<span class=\"ansi-blue-fg\">.</span>createIndex<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#39;bucketSize&#39;</span> <span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-cyan-fg\">10000</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;selectPivotAttempts&#39;</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> end_time <span class=\"ansi-blue-fg\">=</span> process_time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;train&#39; is not defined</div>"]}}],"execution_count":20}],"metadata":{"name":"BigDataTest","notebookId":1518425739103859},"nbformat":4,"nbformat_minor":0}
