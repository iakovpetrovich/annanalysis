{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport os\nimport struct\nimport pandas as pd\nimport time\nfrom time import process_time\nfrom itertools import chain \nimport gc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["import urllib \nurllib.request.urlretrieve(\"ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\", \"/tmp/sift.tar.gz\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: (&#39;/tmp/sift.tar.gz&#39;, &lt;email.message.Message at 0x7f5187820a90&gt;)</div>"]}}],"execution_count":3},{"cell_type":"code","source":["def get_zippedFvecs(pathToGz,memeber):\n    import tarfile\n    fn = pathToGz\n    import struct\n    import numpy as np\n    t = tarfile.open(fn, 'r:gz') \n    \n    \n    m = t.getmember(memeber)\n    file = t.extractfile(m)\n    fileSize = m.size\n    #file =  open(path,'rb')\n    #first 4 bytes of every vector indicate number od dimensions \n    numOfDimensions = struct.unpack('i', file.read(4))[0]\n    #each vector has 4 bytes (float is 32 bits) * numberOfDimensions\n    #plus 4 bytes long indicator as mentioned  \n    numOfVectors = (int) (fileSize / (4 + 4*numOfDimensions))\n    #init empty list for vectors\n    #vectors = []\n    vectors = np.zeros((numOfVectors,numOfDimensions))\n    #return to the beginning\n    file.seek(0)\n    for vecotr in range(numOfVectors):\n        file.read(4) #go trough indicator of dimensions\n        #vectors.append(struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions)))\n        vectors[vecotr] = struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions))\n    file.close()\n    return vectors"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["\ndef get_zippedIvecs(pathToGz,memeber):\n    import tarfile\n    fn = pathToGz\n    import struct\n    import numpy as np\n    t = tarfile.open(fn, 'r:gz') \n    \n    \n    m = t.getmember(memeber)\n    file = t.extractfile(m)\n    fileSize = m.size\n    #file =  open(path,'rb')\n    #first 4 bytes of every vector indicate number od dimensions \n    numOfDimensions = struct.unpack('i', file.read(4))[0]\n    #each vector has 4 bytes (float is 32 bits) * numberOfDimensions\n    #plus 4 bytes long indicator as mentioned  \n    numOfVectors = (int) (fileSize / (4 + 4*numOfDimensions))\n    #init empty list for vectors\n    #vectors = []\n    vectors = np.zeros((numOfVectors,numOfDimensions))\n    #return to the beginning\n    file.seek(0)\n    for vecotr in range(numOfVectors):\n        file.read(4) #go trough indicator of dimensions\n        #vectors.append(struct.unpack('f' * numOfDimensions, file.read(4*numOfDimensions)))\n        vectors[vecotr] = struct.unpack('i' * numOfDimensions, file.read(4*numOfDimensions))\n    file.close()\n    return vectors\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["def returnRecall(result, test):\n    numOfTrueNeighbours = []\n    #for every result vector we check how many right neighbours were identified\n    for i in range(result.shape[0]):\n        numTN = len(set(result[i].tolist()) & set(test[i].tolist()))\n        numOfTrueNeighbours.append(numTN)\n        recall = sum(numOfTrueNeighbours) /test.size\n    return recall"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def fillIfNotAllAreFound(result):\n    for i in range(len(result)):\n        if len(result[i]) < 100: \n            result[i].extend((100-len(result[i])) *[-1]) \n    return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["paths =  '/tmp/sift.tar.gz'  \n\ntrain = get_zippedFvecs(paths,'sift/sift_base.fvecs' )\n#there is 100 querry ponts\nquery = get_zippedFvecs(paths,'sift/sift_query.fvecs' )\n#there is index number of 100 nearset n. for each querry point\ngroundTruth = get_zippedIvecs(paths,'sift/sift_groundtruth.ivecs' )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["rm /tmp/siftsmall.tar.gz"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["algorithm = []\nconstruciotnTimes=[]\nsearchTimes=[]\nreacll = []\nk = 100\navgdistances = []\nconstructionClocks = []\nsearchClocks = []\nclockAlg = []"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["import nmslib\nvptree = nmslib.init(method='vptree', space='l2')\n\nstartTime = process_time()\nvptree.addDataPointBatch(train)\nvptree.createIndex({'bucketSize' : 10000,'selectPivotAttempts':10})\nend_time = process_time()\nconstructionTime = end_time - startTime\n\n# get all nearest neighbours for all the datapoint\n# using a pool of 4 threads to compute\nfor maxLeave in [2,15,25,35]:\n  \n    vptree.setQueryTimeParams({'maxLeavesToVisit':maxLeave,'alphaLeft':1.1,'alphaRight':1.1})\n    startTime = process_time()\n    neighbours = vptree.knnQueryBatch(query,k=100, num_threads=2 )\n    end_time = process_time()\n    searchTime = end_time - startTime\n    \n    rez =[]\n    dist = []\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n        \n    rez = fillIfNotAllAreFound(rez)    \n    \n    result = np.asanyarray(rez)\n    \n    vptreeRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(vptreeRecall)\n    algorithm.append('vp-Tree-10k-mL'+str(maxLeave))\n    #algorithm.append('vp-Tree-maxLeaves'+str(maxLeaves))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    del rez\n    del dist\n    del result\n    gc.collect()\n\n#vptree.saveIndex('vptreeIndex.ann')    \ndel vptree\ngc.collect()\n\n\n#HNSW da bi islo po redu\n#______________________________________________#\nimport nmslib\nfor MMAX in [5,10,30,48]:\n    hnsw = nmslib.init(method='hnsw', space='l2')\n    \n    startClock = time.clock()\n    startTime = process_time()\n    hnsw.addDataPointBatch(train)\n    hnsw.createIndex({'delaunay_type':0, 'M':MMAX})\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    \n    # get all nearest neighbours for all the datapoint\n    # using a pool of 4 threads to compute\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = hnsw.knnQueryBatch(query, k=100, num_threads=2)\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    rez =[]\n    dist =[]\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n    \n    result = fillIfNotAllAreFound(rez)\n      \n    result = np.array(rez)\n    hnswRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(np.sqrt(list(chain.from_iterable(dist))))\n    \n    reacll.append(hnswRecall)\n    algorithm.append('HNSW-M-'+str(MMAX))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    clockAlg.append('HNSW-M-'+str(MMAX))\n    \n    del hnsw\n    del rez\n    del dist\n    del result\n    del neighbours\n    gc.collect()\n\n#______________________________________________#    \n#annoy\n#Annoy\nfrom annoy import AnnoyIndex\nfor trs in [5,60,80,90]:\n    \n    f = train.shape[1]\n    t = AnnoyIndex(f, 'euclidean')\n    \n    startClock= time.clock()\n    startTime = process_time()\n    for i in range(train.shape[0]):\n        t.add_item(i,train[i])\n    t.build(trs)\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    rez = []\n    dist = []\n    startClock = time.clock()\n    startTime = process_time()\n    for q in query:\n        res,d = t.get_nns_by_vector(q, 100, include_distances=True)\n        rez.append(res)\n        dist.append(d)\n        #result.append(t.get_nns_by_vector(q, 100, include_distances=True))\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n        \n    result = fillIfNotAllAreFound(rez)\n    \n    result = np.asanyarray(result)\n    annoyRecall = returnRecall(result, groundTruth)  \n    avgDist = np.mean(list(chain.from_iterable(dist)))\n    \n    reacll.append(annoyRecall)\n    algorithm.append('Annoy-trees-'+str(trs))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    searchClocks.append(searchClock)\n    constructionClocks.append(constructionClock)\n    clockAlg.append('Annoy-trees-'+str(trs))\n    t.save('annoyIndex90.ann')\n    del t\n    del rez\n    del dist\n    del result\n    gc.collect()\n#______________________________________________#\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1518425739103876&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    163</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    164</span> <span class=\"ansi-red-fg\">#flann</span>\n<span class=\"ansi-green-fg\">--&gt; 165</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> pyflann <span class=\"ansi-green-fg\">import</span> <span class=\"ansi-blue-fg\">*</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    166</span> para <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    167</span> <span class=\"ansi-green-fg\">for</span> tp <span class=\"ansi-green-fg\">in</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0.6</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">0.8</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">0.9</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pyflann/__init__.py</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span> <span class=\"ansi-red-fg\">#THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span> \n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> <span class=\"ansi-blue-fg\">.</span>index <span class=\"ansi-green-fg\">import</span> <span class=\"ansi-blue-fg\">*</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-blue-fg\">.</span>io<span class=\"ansi-blue-fg\">.</span>dataset <span class=\"ansi-green-fg\">import</span> load<span class=\"ansi-blue-fg\">,</span> save\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pyflann/index.py</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span> <span class=\"ansi-red-fg\">#THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span> \n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> <span class=\"ansi-blue-fg\">.</span>bindings<span class=\"ansi-blue-fg\">.</span>flann_ctypes <span class=\"ansi-green-fg\">import</span> <span class=\"ansi-blue-fg\">*</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-blue-fg\">.</span>io<span class=\"ansi-blue-fg\">.</span>dataset <span class=\"ansi-green-fg\">import</span> <span class=\"ansi-blue-fg\">*</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> <span class=\"ansi-green-fg\">import</span> numpy<span class=\"ansi-blue-fg\">.</span>random <span class=\"ansi-green-fg\">as</span> _rn\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pyflann/bindings/__init__.py</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> <span class=\"ansi-red-fg\">#from pyflann_parameters import parameter_list, algorithm_names</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> <span class=\"ansi-red-fg\">#from pyflann_parameters import centers_init_names, log_level_names</span>\n<span class=\"ansi-green-fg\">---&gt; 30</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> <span class=\"ansi-blue-fg\">.</span>flann_ctypes <span class=\"ansi-green-fg\">import</span> <span class=\"ansi-blue-fg\">*</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pyflann/bindings/flann_ctypes.py</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    171</span> flannlib <span class=\"ansi-blue-fg\">=</span> load_flann_library<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    172</span> <span class=\"ansi-green-fg\">if</span> flannlib <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 173</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">raise</span> ImportError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Cannot load dynamic library. Did you compile FLANN?&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    174</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    175</span> \n\n<span class=\"ansi-red-fg\">ImportError</span>: Cannot load dynamic library. Did you compile FLANN?</div>"]}}],"execution_count":11},{"cell_type":"code","source":["compareResults = pd.DataFrame({ 'algorithm':algorithm, 'constructionTime':construciotnTimes, 'searchTime':searchTimes,'recall':reacll,'avgDistance':avgdistances, 'constructionClocks':constructionClocks,'searchClocks':searchClocks})"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["compareResults"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithm</th>\n      <th>constructionTime</th>\n      <th>searchTime</th>\n      <th>recall</th>\n      <th>avgDistance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vp-Tree-10k-mL2</td>\n      <td>19.401266</td>\n      <td>15.684920</td>\n      <td>0.0</td>\n      <td>252.022156</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vp-Tree-10k-mL2</td>\n      <td>18.368038</td>\n      <td>15.705375</td>\n      <td>0.0</td>\n      <td>252.476151</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vp-Tree-10k-mL10</td>\n      <td>18.368038</td>\n      <td>76.588221</td>\n      <td>0.0</td>\n      <td>242.125534</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vp-Tree-10k-mL15</td>\n      <td>18.368038</td>\n      <td>114.281209</td>\n      <td>0.0</td>\n      <td>240.751236</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vp-Tree-10k-mL20</td>\n      <td>18.368038</td>\n      <td>151.485374</td>\n      <td>0.0</td>\n      <td>238.824493</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>vp-Tree-10k-mL25</td>\n      <td>18.368038</td>\n      <td>188.059627</td>\n      <td>0.0</td>\n      <td>238.173386</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vp-Tree-10k-mL30</td>\n      <td>18.368038</td>\n      <td>225.625846</td>\n      <td>0.0</td>\n      <td>237.831680</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HNSW-M-2</td>\n      <td>281.885477</td>\n      <td>0.578932</td>\n      <td>0.0</td>\n      <td>352.396820</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HNSW-M-5</td>\n      <td>485.369821</td>\n      <td>1.032199</td>\n      <td>0.0</td>\n      <td>257.530518</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HNSW-M-8</td>\n      <td>657.970270</td>\n      <td>1.349002</td>\n      <td>0.0</td>\n      <td>249.655685</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HNSW-M-15</td>\n      <td>1009.236386</td>\n      <td>1.984721</td>\n      <td>0.0</td>\n      <td>242.332382</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HNSW-M-30</td>\n      <td>1715.614691</td>\n      <td>3.007280</td>\n      <td>0.0</td>\n      <td>238.463867</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HNSW-M-40</td>\n      <td>2232.284778</td>\n      <td>3.635444</td>\n      <td>0.0</td>\n      <td>237.665131</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Annoy-trees-5</td>\n      <td>33.757526</td>\n      <td>1.717466</td>\n      <td>0.0</td>\n      <td>254.695136</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Annoy-trees-15</td>\n      <td>60.237308</td>\n      <td>3.661673</td>\n      <td>0.0</td>\n      <td>243.330537</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Annoy-trees-30</td>\n      <td>100.123436</td>\n      <td>6.240144</td>\n      <td>0.0</td>\n      <td>239.467808</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Annoy-trees-45</td>\n      <td>140.168586</td>\n      <td>8.961836</td>\n      <td>0.0</td>\n      <td>238.086923</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Annoy-trees-60</td>\n      <td>179.095409</td>\n      <td>11.430758</td>\n      <td>0.0</td>\n      <td>237.402157</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Annoy-trees-80</td>\n      <td>236.837507</td>\n      <td>14.303112</td>\n      <td>0.0</td>\n      <td>236.893282</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Annoy-trees-90</td>\n      <td>267.719928</td>\n      <td>16.155166</td>\n      <td>0.0</td>\n      <td>236.731843</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["import nmslib\nfor MMAX in [5,10,30,48]:\n    hnsw = nmslib.init(method='hnsw', space='l2')\n    \n    startClock = time.clock()\n    startTime = process_time()\n    hnsw.addDataPointBatch(train)\n    hnsw.createIndex({'delaunay_type':0, 'M':MMAX})\n    end_time = process_time()\n    constructionTime = end_time - startTime\n    endClock = time.clock()\n    constructionClock= endClock - startClock\n    \n    \n    \n    # get all nearest neighbours for all the datapoint\n    # using a pool of 4 threads to compute\n    startClock = time.clock()\n    startTime = process_time()\n    neighbours = hnsw.knnQueryBatch(query, k=100, num_threads=2)\n    end_time = process_time()\n    searchTime = end_time - startTime\n    endClock = time.clock()\n    searchClock= endClock - startClock\n    \n    rez =[]\n    dist =[]\n    for i in neighbours:\n        rez.append(list(i[0]))\n        dist.append(list(i[1]))\n    \n    result = fillIfNotAllAreFound(rez)\n      \n    result = np.array(rez)\n    hnswRecall = returnRecall(result, groundTruth)\n    avgDist = np.mean(np.sqrt(list(chain.from_iterable(dist))))\n    \n    reacll.append(hnswRecall)\n    algorithm.append('HNSW-M-'+str(MMAX))\n    construciotnTimes.append(constructionTime)\n    searchTimes.append(searchTime)\n    avgdistances.append(avgDist)\n    constructionClocks.append(constructionClock)\n    searchClocks.append(searchClock)\n    clockAlg.append('HNSW-M-'+str(MMAX))\n    \n    del hnsw\n    del rez\n    del dist\n    del result\n    del neighbours\n    gc.collect()\n"],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"BigDataTest","notebookId":1518425739103859},"nbformat":4,"nbformat_minor":0}
